{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a091b15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline \n",
    "from tensorflow.keras.preprocessing import text , sequence \n",
    "from tensorflow.keras.layers import Dense , LSTM   , Input ,Bidirectional ,Dropout\n",
    "from tensorflow.keras.models import Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "105ce64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# load the data \n",
    "path = 'C:/Users/DELL/Downloads/football-match-probability-prediction'\n",
    "train_data = pd.read_csv(os.path.join(path , 'train.csv'))\n",
    "test_data = pd.read_csv(os.path.join(path , 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2b5ba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting date to useful features \n",
    "def convert_date(data): \n",
    "    data['match_date'] = pd.to_datetime(data['match_date'])\n",
    "    \n",
    "    for i in range(1,11) : \n",
    "        data[f'home_team_history_match_date_{i}'] = pd.to_datetime(data[f'home_team_history_match_date_{i}'])\n",
    "        data[f'away_team_history_match_date_{i}'] = pd.to_datetime(data[f'home_team_history_match_date_{i}'])\n",
    "        \n",
    "    for i in range(1,11) : \n",
    "        data[f'home_time_difference_between_two_matches_{i}'] = (data['match_date'] - data[f'home_team_history_match_date_{i}'] ).dt.days\n",
    "        data[f'away_time_difference_between_two_matches_{i}'] = (data['match_date'] - data[f'away_team_history_match_date_{i}'] ).dt.days\n",
    "        data = data.drop(f'home_team_history_match_date_{i}' , axis =1)\n",
    "        data = data.drop(f'away_team_history_match_date_{i}' , axis =1)\n",
    "        \n",
    "    data = data.drop('match_date' , axis =1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5592d41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we get the ratio between the days and number of matches played in this days \n",
    "def matches_span(data):\n",
    "    data['home_team_exhaustion'] = data['home_time_difference_between_two_matches_10'] / 10 \n",
    "    data['away_team_exhaustion'] = data['away_time_difference_between_two_matches_10'] / 10\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cdb3c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the average scoring for the two teams throw the 10 matches \n",
    "# and the average opponent scoring aganist the two teams \n",
    "def average_scoring(data) :\n",
    "    data['home_team_average_scoreing'] = 0 \n",
    "    data['away_team_average_scoreing'] = 0 \n",
    "    data['home_opponent_average_scoreing'] = 0\n",
    "    data['away_opponent_average_scoreing'] = 0\n",
    "    for i in range(1,11) : \n",
    "        data['home_team_average_scoreing'] += data[f'home_team_history_goal_{i}']\n",
    "        data['away_team_average_scoreing'] += data[f'home_team_history_goal_{i}']\n",
    "    \n",
    "        data['home_opponent_average_scoreing'] += data[f'home_team_history_opponent_goal_{i}']\n",
    "        data['away_opponent_average_scoreing'] += data[f'away_team_history_opponent_goal_{i}']\n",
    "    \n",
    "    data['home_team_average_scoreing'] /= 10 \n",
    "    data['away_team_average_scoreing'] /= 10 \n",
    "    data['home_opponent_average_scoreing'] /= 10\n",
    "    data['away_opponent_average_scoreing'] /= 10\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfcb58b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ratio of winning for each team \n",
    "def who_win(data) : \n",
    "    data['home_team_average_winning_rate'] = 0\n",
    "    data['away_team_average_winning_rate'] = 0\n",
    "    for i in range(1 , 11 ) : \n",
    "        data[f'home_target_match{i}'] = data[f'home_team_history_goal_{i}'] - data[f'home_team_history_opponent_goal_{i}']\n",
    "        data[f'away_target_match{i}'] = data[f'away_team_history_goal_{i}'] - data[f'away_team_history_opponent_goal_{i}']\n",
    "    for i in range(1,11) : \n",
    "        data[f'home_target_match{i}'] =  data[f'home_target_match{i}'].apply(lambda X : 1 if X > 0 else 0)\n",
    "        data[f'away_target_match{i}'] =  data[f'away_target_match{i}'].apply(lambda X : 1 if X > 0 else 0)\n",
    "    for i in range(1 ,11 ) : \n",
    "        data['home_team_average_winning_rate'] += data[f'home_target_match{i}'] \n",
    "        data['away_team_average_winning_rate'] += data[f'away_target_match{i}']\n",
    "        data = data.drop(f'home_target_match{i}', axis = 1 )\n",
    "        data = data.drop(f'away_target_match{i}', axis = 1 )\n",
    "    data['home_team_average_winning_rate'] /= 10\n",
    "    data['away_team_average_winning_rate'] /= 10\n",
    "    return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72a8b9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this pipeline deal with the missing data and scale the data \n",
    "steps = [('imputer', SimpleImputer(strategy = 'mean')), ('scaler', StandardScaler())]\n",
    "pip = Pipeline(steps) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c06cc1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the text columns \n",
    "text_columns = ['home_team_name' , 'away_team_name' , 'league_name']\n",
    "max_f = 1000\n",
    "max_len = 5 \n",
    "def process_text(data) : \n",
    "    tock = text.Tokenizer(max_f)\n",
    "    tock.fit_on_texts(data)\n",
    "    data = tock.texts_to_sequences(data)\n",
    "    data = sequence.pad_sequences(data , maxlen = max_len)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67ac490f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_process(train_data) : \n",
    "    # rid of any rows with out the teams name because useless\n",
    "    train_data = train_data[ (train_data['home_team_name'].isna() == False ) & (train_data['away_team_name'].isna() == False ) ].reset_index(drop=True)\n",
    "    train_data = convert_date(train_data)\n",
    "    train_data['is_cup'] = train_data['is_cup'].apply(lambda X : 0 if X == False else 1)\n",
    "    train_data = matches_span(train_data)\n",
    "    train_data = average_scoring(train_data)\n",
    "    train_data = who_win(train_data)\n",
    "    # map the target columns to labels \n",
    "    train_labels = pd.get_dummies(train_data['target'] )\n",
    "    train_data = train_data.drop('target' , axis = 1) \n",
    "    #scaling the data \n",
    "    scaled_train_data = pip.fit_transform(train_data.iloc[: , 5:])\n",
    "    # process the text_data \n",
    "    processed_train_text = np.concatenate([process_text(train_data[col]) for col in text_columns ] , axis = 1)\n",
    "    # concat the scaled data with the processed text \n",
    "    train_processed_data = np.concatenate([scaled_train_data ,processed_train_text ] , axis = 1 )\n",
    "    return train_processed_data , train_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4be90028",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , y_train = train_data_process(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8174a1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_process(test_data_f) : \n",
    "    test_data_f = convert_date(test_data_f)\n",
    "    test_data_f['is_cup'] = test_data_f['is_cup'].apply(lambda X : 0 if X == False else 1)\n",
    "    test_data_f = matches_span(test_data_f)\n",
    "    test_data_f = average_scoring(test_data_f)\n",
    "    test_data_f = who_win(test_data_f)\n",
    "    scaled_test_data = pip.transform(test_data_f.iloc[: , 5:])\n",
    "    processed_test_text = np.concatenate([process_text(test_data_f[col]) for col in text_columns ] , axis = 1)\n",
    "    test_processed_data = np.concatenate([scaled_test_data ,processed_test_text ] , axis = 1 )\n",
    "    return test_processed_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdc1094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data_process(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ad64fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_val , y_train, y_val = train_test_split(X_train , y_train , test_size = .1 , random_state =123 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b04baf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add dummy axis to the data to match the model expected shape \n",
    "X_train = X_train[: ,: ,np.newaxis]\n",
    "X_val = X_val[: ,: ,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76fee29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=X_train.shape[1:])\n",
    "\n",
    "X = Bidirectional(LSTM(16, return_sequences=True, activation='tanh'))(inputs)\n",
    "X = tf.keras.layers.BatchNormalization()(X)\n",
    "X = Bidirectional(LSTM(8, return_sequences=True, activation='tanh'))(X)\n",
    "X = tf.keras.layers.BatchNormalization()(X)\n",
    "X = tf.keras.layers.Flatten()(X)\n",
    "X = Dense(64 , activation ='tanh')(X)\n",
    "X = Dense(3 ,activation ='softmax')(X)\n",
    "model = Model(inputs , X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96603c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer ='adam' , loss ='categorical_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "faddca9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1561/1561 [==============================] - 451s 282ms/step - loss: 1.0461 - accuracy: 0.4769 - val_loss: 1.0195 - val_accuracy: 0.4910\n",
      "Epoch 2/30\n",
      "1561/1561 [==============================] - 459s 294ms/step - loss: 1.0219 - accuracy: 0.4893 - val_loss: 1.0197 - val_accuracy: 0.4900\n",
      "Epoch 3/30\n",
      "1561/1561 [==============================] - 388s 249ms/step - loss: 1.0178 - accuracy: 0.4926 - val_loss: 1.0151 - val_accuracy: 0.4932\n",
      "Epoch 4/30\n",
      "1561/1561 [==============================] - 359s 230ms/step - loss: 1.0175 - accuracy: 0.4935 - val_loss: 1.0165 - val_accuracy: 0.4919\n",
      "Epoch 5/30\n",
      "1561/1561 [==============================] - 365s 234ms/step - loss: 1.0166 - accuracy: 0.4932 - val_loss: 1.0129 - val_accuracy: 0.4957\n",
      "Epoch 6/30\n",
      "1561/1561 [==============================] - 377s 241ms/step - loss: 1.0140 - accuracy: 0.4965 - val_loss: 1.0158 - val_accuracy: 0.4956\n",
      "Epoch 7/30\n",
      "1561/1561 [==============================] - 437s 280ms/step - loss: 1.0131 - accuracy: 0.4967 - val_loss: 1.0146 - val_accuracy: 0.4968\n",
      "Epoch 8/30\n",
      "1561/1561 [==============================] - 421s 270ms/step - loss: 1.0113 - accuracy: 0.4976 - val_loss: 1.0137 - val_accuracy: 0.4940\n",
      "Epoch 9/30\n",
      "1561/1561 [==============================] - 422s 270ms/step - loss: 1.0098 - accuracy: 0.5000 - val_loss: 1.0138 - val_accuracy: 0.5003\n",
      "Epoch 10/30\n",
      "1561/1561 [==============================] - 387s 248ms/step - loss: 1.0087 - accuracy: 0.4989 - val_loss: 1.0137 - val_accuracy: 0.4970\n",
      "Epoch 11/30\n",
      "1561/1561 [==============================] - 389s 249ms/step - loss: 1.0074 - accuracy: 0.5003 - val_loss: 1.0147 - val_accuracy: 0.4968\n",
      "Epoch 12/30\n",
      "1561/1561 [==============================] - 389s 249ms/step - loss: 1.0054 - accuracy: 0.5023 - val_loss: 1.0131 - val_accuracy: 0.5007\n",
      "Epoch 13/30\n",
      "1561/1561 [==============================] - 378s 242ms/step - loss: 1.0030 - accuracy: 0.5034 - val_loss: 1.0139 - val_accuracy: 0.4991\n",
      "Epoch 14/30\n",
      "1561/1561 [==============================] - 397s 254ms/step - loss: 1.0013 - accuracy: 0.5049 - val_loss: 1.0133 - val_accuracy: 0.4986\n",
      "Epoch 15/30\n",
      "1561/1561 [==============================] - 416s 267ms/step - loss: 0.9984 - accuracy: 0.5089 - val_loss: 1.0166 - val_accuracy: 0.4933\n",
      "Epoch 16/30\n",
      "1561/1561 [==============================] - 392s 251ms/step - loss: 0.9957 - accuracy: 0.5098 - val_loss: 1.0157 - val_accuracy: 0.5040\n",
      "Epoch 17/30\n",
      "  51/1561 [..............................] - ETA: 6:08 - loss: 0.9921 - accuracy: 0.5107"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9204/23578260.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train,  validation_data =(X_val , y_val),epochs = 30 ,batch_size =64 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f81984e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63e29ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>away</th>\n",
       "      <th>draw</th>\n",
       "      <th>home</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17761448</td>\n",
       "      <td>0.363812</td>\n",
       "      <td>0.249806</td>\n",
       "      <td>0.386382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17695487</td>\n",
       "      <td>0.252411</td>\n",
       "      <td>0.314528</td>\n",
       "      <td>0.433061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17715496</td>\n",
       "      <td>0.372683</td>\n",
       "      <td>0.270427</td>\n",
       "      <td>0.356891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17715493</td>\n",
       "      <td>0.589213</td>\n",
       "      <td>0.268732</td>\n",
       "      <td>0.142055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17715492</td>\n",
       "      <td>0.195901</td>\n",
       "      <td>0.286983</td>\n",
       "      <td>0.517116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72706</th>\n",
       "      <td>18450246</td>\n",
       "      <td>0.299968</td>\n",
       "      <td>0.343341</td>\n",
       "      <td>0.356691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72707</th>\n",
       "      <td>18164889</td>\n",
       "      <td>0.159855</td>\n",
       "      <td>0.222598</td>\n",
       "      <td>0.617547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72708</th>\n",
       "      <td>18449018</td>\n",
       "      <td>0.672934</td>\n",
       "      <td>0.232117</td>\n",
       "      <td>0.094948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72709</th>\n",
       "      <td>17958831</td>\n",
       "      <td>0.179605</td>\n",
       "      <td>0.261150</td>\n",
       "      <td>0.559245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72710</th>\n",
       "      <td>18441629</td>\n",
       "      <td>0.207211</td>\n",
       "      <td>0.328553</td>\n",
       "      <td>0.464237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72711 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id      away      draw      home\n",
       "0      17761448  0.363812  0.249806  0.386382\n",
       "1      17695487  0.252411  0.314528  0.433061\n",
       "2      17715496  0.372683  0.270427  0.356891\n",
       "3      17715493  0.589213  0.268732  0.142055\n",
       "4      17715492  0.195901  0.286983  0.517116\n",
       "...         ...       ...       ...       ...\n",
       "72706  18450246  0.299968  0.343341  0.356691\n",
       "72707  18164889  0.159855  0.222598  0.617547\n",
       "72708  18449018  0.672934  0.232117  0.094948\n",
       "72709  17958831  0.179605  0.261150  0.559245\n",
       "72710  18441629  0.207211  0.328553  0.464237\n",
       "\n",
       "[72711 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.DataFrame({\n",
    "    'id': test_data['id'],\n",
    "    'away': preds[:, 0],\n",
    "    'draw': preds[:, 1],\n",
    "    'home': preds[:, 2]\n",
    "})\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28023b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('sub_2.csv' , index =False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
